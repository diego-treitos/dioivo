#!/usr/bin/env python
# -*- coding:utf8 -*-
#
#  PyWench. A log driven web benchmarking tool.
#  Copyright (C) 2014  Diego Blanco
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, version 2 of the License.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program.  If not, see <http://www.gnu.org/licenses/>.
#

import urllib3, httplib
import time
from threading import Thread, Lock
from random import Random
import Gnuplot
import sys
import pprint
from optparse import OptionParser


DEBUG=False
SOCKET_TIMEOUT=90

R_LOCK=Lock()
W_LOCK=Lock()

def get_connection_pool( host, http_version=11, auth_rule=None ):
    if http_version == 10:
        httplib.HTTPConnection._http_vsn = 10
        httplib.HTTPConnection._http_vsn_str = 'HTTP/1.0'
    elif http_version == 11:
        httplib.HTTPConnection._http_vsn = 11
        httplib.HTTPConnection._http_vsn_str = 'HTTP/1.1'
    else:
        raise PywenchException('Bad HTTP version: %s' % repr(http_version))

    if not auth_rule:
        cpool = urllib3.connectionpool.connection_from_url(host)
    else:
        try:
            auth = auth_rule.split('::')
            method=auth[0]
            url=auth[1]
            
            if url[:7].lower() != 'http://' or url[:8].lower() != 'https://':
                raise PywenchException('Bad authentication rule syntax: URL does not start by http:// or https://')

            params={}
            for p in auth[2:]:
                [k,v] = p.split('=')
                params[k]=v

            tpool = urllib3.connectionpool.connection_from_url(url)
            # Disable certificate verification for auth
            tpool.cert_reqs = 'CERT_NONE'
            tpool.ca_certs = None

            if method.lower() == 'get':
                r = tpool.request('GET','%s?%s' % (url,'&'.join(auth[2:])))
                cookie = r.getheader('set-cookie')
            elif method.lower() == 'post':
                r = tpool.request('POST','%s',fields=params)
                cookie = r.getheader('set-cookie')
            else:
                raise PywenchException('Bad authentication rule syntax: Only POST or GET methods allowed.')

            cpool = urllib3.connectionpool.connection_from_url(host, headers={'cookie':cookie})

        except IndexError:
            raise PywenchException('Bad authentication rule syntax')

    # Disable certificate verification for all connections
    cpool.cert_reqs = 'CERT_NONE'
    cpool.ca_certs = None

    return cpool

def print_debug( msg, new_line=True):
    if new_line:
        print msg
    else:
        print msg,
    sys.stdout.flush()


class PywenchException(Exception):
    def __init__(self, msg):
        self.val = msg

    def __str__(self):
        return repr( self.val )


class WebClient(Thread):

    def __init__(self, url_provider, data_manager, connection_pool ):
        super(WebClient, self).__init__()
        self.__stop = None

        self.url_provider = url_provider
        self.data_manager = data_manager
        self.cpool = connection_pool

        self.debug=DEBUG
        self.n=None

    def stop(self):
        if self.__stop == False:
            self.__stop=True
        
    def get_times(self, _url):
        try:
            start = time.time()
            r = None
            r = self.cpool.urlopen('GET', _url, retries=0, redirect=False, release_conn=False, preload_content=False, timeout=SOCKET_TIMEOUT)

            # get http code
            code = r.status

            # ttfb (time to first byte)
            r.read(1)
            ttfb = time.time() - start
            # ttlb (time to last byte)
            r.read()
            ttlb = time.time() - start

        except Exception as e:
            if not isinstance(e, (urllib3.exceptions.MaxRetryError)) and self.debug:
                print_debug("\n[%d] Exception occurred: %s\n" % (self.n, e.__repr__()))

            # In case of exception, set code=None so it does not affect timing stats
            code = None
            ttfb = 0
            ttlb = 0

        finally:
            # Release connection so the pool can continue doing requests
            if r is not None: r.release_conn()

            return {
                    'time': start,
                    'url': _url,
                    'code': code,
                    'ttfb': ttfb,
                    'ttlb': ttlb
                    }

    def run(self):
        if self.debug: print_debug('%d: starting thread...' % self.n)
        self.__stop = False
        while not self.__stop:
            if self.debug: print_debug('%d: pre-r' % self.n)
            R_LOCK.acquire()
            if self.debug: print_debug('%d: getting url... ' % self.n)
            url = self.url_provider.get_url()
            if self.debug: print_debug('%d: url: %s... ' % (self.n, url))
            R_LOCK.release()
            if self.debug: print_debug('%d: post-r' % self.n)
            if url == None:
                if self.debug: print_debug('%d: stopping thread...' % self.n)
                self.stop()
                if self.debug: print_debug('%d: stopped !!' % self.n)
            else:
                if self.debug: print_debug('%d: getting data... ' % self.n)
                d = self.get_times( url )
                if self.debug: print_debug('%d: data: %s... ' % (self.n, repr(d)))
                if self.debug: print_debug('%d: pre-w' % self.n)
                W_LOCK.acquire()
                if self.debug: print_debug('%d: adding data... ' % self.n)
                self.data_manager.add_data( d )
                if self.debug: print_debug('%d: data added.' % self.n)
                W_LOCK.release()
                if self.debug: print_debug('%d: post-w' % self.n)


class UrlProvider(object):

    def __init__(self, urls_file_path, mode, requests_number, replace_parameter_list=[]):
        """mode = [random,squence]"""
        try:
            self.urls = self.__filter_urls(urls_file_path)
        except IOError:
            raise PywenchException('Unable to open file: %s' % urls_file_path)
    
        if mode.lower() not in ('random','sequence'):
            raise PywenchException('Invalid url choosing mode')

        self.mode = mode.lower()
        self.requests_number = requests_number
        self.__n_urls = self.urls.__len__()
        self.__url_index = None
        self.replace_parameter_dict = {}
        self.__parse_replace_parameter( replace_parameter_list )

    def __parse_replace_parameter(self, rpl):
        for rp in rpl:
            npk,npv = rp.split('=')
            self.replace_parameter_dict[npk] = npv

    def __filter_urls(self, access_file):
        urls = []
        lines = open(access_file).readlines()
        for l in lines:
            if l.find('GET') != -1:
                urls.append(l.split()[6])
        return urls


    def get_url(self):
        if self.requests_number <= 0:
            url = None
        else:
            if self.mode == 'random':
                r = Random()
                u = self.urls[ r.randint(0, self.__n_urls-1) ]
            elif self.mode == 'sequence':
                # (Re)set the index
                if self.__url_index == None or self.__url_index == self.__n_urls-1:
                    self.__url_index = -1 
                self.__url_index+=1 
                u = self.urls[ self.__url_index ]
            
            url = u.strip()

            # If url is not a relative path, search for other url
            if url[:7].lower() == "http://" or url[:8].lower() == "https://":
                return self.get_url()

            # Decrease the number of requests to serve
            self.requests_number-=1

            if self.replace_parameter_dict != {} and url.find('?') != -1:
                [rawurl,rawp] = url.split('?')
                params='?'
                for p in rawp.split('&'):
                    [k,v]=p.split('=')
                    if self.replace_parameter_dict.has_key(k):
                        params+="%s=%s&" % (k,self.replace_parameter_dict[k])
                    else:
                        params+="%s=%s&" % (k,v)
                # remove last &
                params=params[:-1]
                return rawurl+params


        return url


class DataManager(object):

    def __init__(self, total_requests, concurrency, http_version):
        self.data = {}

        self.total_requests = total_requests
        self.concurrency = concurrency
        self.http_version = http_version

        self.ttfb_graph = []
        self.ttlb_graph = []
        self.ttfb_plot = None
        self.ttlb_plot = None
        self.gp = None
        self.stat = None



    def add_data(self, d):
        self.data[d['time']] = d
        self.ttfb_graph.append( [self.ttfb_graph.__len__()+1, d['ttfb']] )
        self.ttlb_graph.append( [self.ttlb_graph.__len__()+1, d['ttlb']] )
        if not self.gp:
            # Initialize gnuplot
            self.gp = Gnuplot.Gnuplot()
            # Uncomment and comment x11 lines for ascii art
            #self.gp('set terminal dumb 144 69')
            self.gp('set terminal x11 noraise nopersist')
            self.gp('set terminal x11 size "800,600"')
            self.gp('set terminal x11 position "0,0"')

    def save(self, filenames_prefix='output'):
        f = file(filenames_prefix+'.csv','w')
        dkeys = self.data.keys()
        dkeys.sort()
        f.write('time\t\turl\t\tttfb\t\tttlb\n')
        for k in dkeys:
            f.write('%f\t\t%s\t\t%f\t\t%f\n' % ( self.data[k]['time'],self.data[k]['url'],self.data[k]['ttfb'],self.data[k]['ttlb']))
        f.close()
        f = file(filenames_prefix+'.stat','w')
        pprint.pprint(self.stat, stream=f)
        f.close()

        self.replot()
        self.gp.hardcopy(filename=filenames_prefix+'.png', terminal='png')
        self.gp.close()
        self.gp.__del__()


    def stats(self):
        self.stat={
                'ttfb':{
                    'min':None,
                    'avg':None,
                    'max':None
                    },
                'ttlb':{
                    'min':None,
                    'avg':None,
                    'max':None
                    },
                'url':{
                    'min_ttfb':None,
                    'max_ttfb':None,
                    'min_ttlb':None,
                    'max_ttlb':None
                    },
                'code':{
                    },
                'rps':None
                }
       
        # Stats for TTFB and TTLB
        count=0
        for d in self.data:
            # Init codes
            if self.stat['code'].has_key(self.data[d]['code']):
                self.stat['code'][self.data[d]['code']]+=1
            else:
                self.stat['code'][self.data[d]['code']]=1

            # Avoid failed request to affect stats
            if self.data[d]['code'] == None:
                continue

            count+=1
            # Init
            if self.stat['ttfb']['min'] == None:
                self.stat['ttfb']['min'] = self.data[d]['ttfb']
                self.stat['ttfb']['avg'] = self.data[d]['ttfb']
                self.stat['ttfb']['max'] = self.data[d]['ttfb']
                self.stat['ttlb']['min'] = self.data[d]['ttlb']
                self.stat['ttlb']['avg'] = self.data[d]['ttlb']
                self.stat['ttlb']['max'] = self.data[d]['ttlb']
            else:
                # Min
                if self.data[d]['ttfb'] < self.stat['ttfb']['min']:
                    self.stat['ttfb']['min'] = self.data[d]['ttfb']
                if self.data[d]['ttlb'] < self.stat['ttlb']['min']:
                    self.stat['ttlb']['min'] = self.data[d]['ttlb']

                # Max 
                if self.data[d]['ttfb'] > self.stat['ttfb']['max']:
                    self.stat['ttfb']['max'] = self.data[d]['ttfb']
                if self.data[d]['ttlb'] > self.stat['ttlb']['max']:
                    self.stat['ttlb']['max'] = self.data[d]['ttlb']
                
                # Avg
                self.stat['ttfb']['avg'] = self.stat['ttfb']['avg'] + (self.data[d]['ttfb']-self.stat['ttfb']['avg'])/float(count)
                self.stat['ttlb']['avg'] = self.stat['ttlb']['avg'] + (self.data[d]['ttlb']-self.stat['ttlb']['avg'])/float(count)


        # self.stats for URL
        ud = {}
        for d in self.data:
            if not ud.has_key( self.data[d]['url'] ):
                # Init ud for new url with ttfb, ttlb and the count of url occurrences (for mean calculation)
                ud[self.data[d]['url']]=[ self.data[d]['ttfb'], self.data[d]['ttlb'], 1]
            else:
                # Calculate mean values for ttfb and ttlb for this url
                ud[self.data[d]['url']][2] += 1
                count = ud[self.data[d]['url']][2]
                # 0: ttfb mean for this url
                ud[self.data[d]['url']][0] = ud[self.data[d]['url']][0] +  (self.data[d]['ttfb'] - ud[self.data[d]['url']][0])/count
                # 1: ttlb mean for this url
                ud[self.data[d]['url']][1] = ud[self.data[d]['url']][1] +  (self.data[d]['ttlb'] - ud[self.data[d]['url']][1])/count

        for k in ud:
            # Init
            if not self.stat['url']['min_ttfb']:
                self.stat['url']['min_ttfb'] = (ud[k][0],k)
                self.stat['url']['max_ttfb'] = (ud[k][0],k)
                self.stat['url']['min_ttlb'] = (ud[k][1],k)
                self.stat['url']['max_ttlb'] = (ud[k][1],k)
            else:
                if ud[k][0] < self.stat['url']['min_ttfb'][0]:
                    self.stat['url']['min_ttfb']=(ud[k][0],k)
                if ud[k][0] > self.stat['url']['max_ttfb'][0]:
                    self.stat['url']['max_ttfb']=(ud[k][0],k)
                if ud[k][1] < self.stat['url']['min_ttlb'][0]:
                    self.stat['url']['min_ttlb']=(ud[k][1],k)
                if ud[k][1] > self.stat['url']['max_ttlb'][0]:
                    self.stat['url']['max_ttlb']=(ud[k][1],k)

        # get requests per second
        self.stat['rps']=self.concurrency/self.stat['ttlb']['avg']

        return self.stat

    def replot(self):
        if self.gp:
            self.ttfb_plot = Gnuplot.PlotItems.Data(self.ttfb_graph, with_="lines lt rgb '#7733aa44' lw 1", smooth='unique', title="ttfb")
            self.ttlb_plot = Gnuplot.PlotItems.Data(self.ttlb_graph, with_="lines lt rgb '#773344aa' lw 1", smooth='unique', title="ttlb")
            self.gp.reset()
            self.gp.title('Requests: %d   User concurrency: %d   HTTP %.1f ' % (self.total_requests, self.concurrency, self.http_version/10.))
            self.gp('set grid y')
            self.gp('set ytics mirror autofreq')
            self.gp('set ytics font ",10.0"')
            self.gp.xlabel("requests")
            self.gp.ylabel("response time (seconds)")
            self.gp.replot(self.ttfb_plot, self.ttlb_plot)



def pw_getopts():
    parser = OptionParser(usage="usage: %prog [options] -s SERVER -u URLS_FILE -c CONCURRENCY -n NUMBER_OF_REQUESTS")

    parser.add_option("-i", "--test-id",
            action="store",
            dest="test_id",
            type="string",
            default=False,
            help="Identificator for the test. This name will be a suffix for the output files.")

    parser.add_option("-s", "--server",
            action="store",
            dest="server",
            type="string",
            default=None,
            help="Server to benchmark. It must include the protocol and lack of trailing slash. For example: https://example.com")
    
    parser.add_option("-u", "--urls",
            action="store",
            dest="urls_file",
            type="string",
            default=False,
            help="File with url's to test. This file must be directly an access.log file from nginx or apache.'")
    
    parser.add_option("-c", "--concurrency",
            action="store",
            dest="concurrency",
            type="int",
            default=False,
            help="Number of concurrent requests")
    
    parser.add_option("-n", "--number-of-requests",
            action="store",
            dest="total_requests",
            type="int",
            default=False,
            help="Number of requests to send to the host.")
    
    parser.add_option("-m", "--mode",
            action="store",
            dest="mode",
            type="string",
            default='random',
            help="Mode can be 'random' or 'sequence'. It defines how the urls will be chosen from the url's file.")
    
    parser.add_option("-R", "--replace-parameter",
            action="append",
            dest="replace_parameter",
            type="string",
            default=[],
            help="Replace parameter on the URLs that have such parameter: p.e.: 'user=hackme' will set the parameter 'user' to 'hackme' on all url that have the 'user' parameter. Can be called several times to make multiple replacements.")
    
    parser.add_option("-A", "--auth",
            action="store",
            dest="auth_rule",
            type="string",
            default=None,
            help="Adds rule for form authentication with cookies. Syntax: 'METHOD::URL[::param1=value1[::param2=value2]...]'. For example: 'POST::http://example.com/login.py::user=root::pass=hackme'. NOTE: Use full url with protocol as in the example.")
    
    parser.add_option("-H", "--http-version",
            action="store",
            dest="http_version",
            type="int",
            default='11',
            help="Defines which protocol version to use. Use '11' for HTTP 1.1 and '10' for HTTP 1.0")
    
    parser.add_option("-l", "--live",
            action="store_true",
            dest="dynamic_plot",
            default=False,
            help="If you enable this flag, you'll be able to see the realtime plot of the benchmark")

    (opts, args) = parser.parse_args()

    if not opts.server:
        parser.error('Missing server to test (-s)')
    if not opts.urls_file:
        parser.error('Missing file with urls (-u)')
    if not opts.concurrency:
        parser.error('Concurrency not given (-c)')
    if not opts.total_requests:
        parser.error('Number of requests not given (-n)')

    return opts
    
def pw_main( opts ):
    # Set parameters
    urls_file=opts.urls_file
    mode=opts.mode
    total_requests=opts.total_requests
    concurrency=opts.concurrency
    host=opts.server
    http_version=opts.http_version
    dynamic_plot=opts.dynamic_plot
    replace_parameter=opts.replace_parameter
    replace_parameter
    auth_rule=opts.auth_rule
    test_id=opts.test_id

    # Create needed instances
    up = UrlProvider(urls_file,mode, total_requests, replace_parameter_list=replace_parameter)
    dm = DataManager(total_requests, concurrency, http_version)
    cp = get_connection_pool( host, http_version, auth_rule )

    # Create threads for concurrency
    ts = []
    for t in xrange(concurrency):
        ts.append( WebClient(up,dm,cp))

    # Start Threads
    # Aquire read lock so we ensure all threads start the benchmark
    # at the same time.
    R_LOCK.acquire()
    i=1
    for t in ts:
        t.n=i
        i+=1
        t.start()
    R_LOCK.release()


    print "\n Requests: %d\t\tConcurrency: %d\n" % (total_requests, ts.__len__())
    # bs: progress bar size
    bs=50
   
    # Main loop with progress bar and plotting
    time.sleep(1)
    while up.requests_number > 0:
        per=(up.requests_number*bs)/total_requests
        print '[%s%s] ' % ('='*(bs-per),' '*per),
        sys.stdout.flush()
        time.sleep(0.5)
        print '\r',
        sys.stdout.flush()
        if dynamic_plot: dm.replot()
    print '[%s] ' % ('='*bs)
    sys.stdout.flush()

    # Stopping threads
    print ""
    print "Stopping... ",
    sys.stdout.flush()
    # First call stop for each thread
    for t in ts:
        t.stop()
    # Then wait for all threads to stop
    for t in ts:
        print t.n,
        sys.stdout.flush()
        t.join()
        print "\b"*(str(t.n).__len__()+2),
        sys.stdout.flush()
    print "DONE"
    sys.stdout.flush()


    print "\nCompiling stats...",
    sys.stdout.flush()
    stats = dm.stats()
    print "DONE"
    sys.stdout.flush()

    print '\nStats (seconds)\n'
    print '\t\tmin\t\tavg\t\tmax'
    print 'ttfb\t\t%.5f\t\t%.5f\t\t%.5f' % (stats['ttfb']['min'],stats['ttfb']['avg'],stats['ttfb']['max'])
    print 'ttlb\t\t%.5f\t\t%.5f\t\t%.5f' % (stats['ttlb']['min'],stats['ttlb']['avg'],stats['ttlb']['max'])
    print '\n'
    print 'Requests per second: %.3f' % stats['rps']
    print '\n'
    print 'URL min ttfb: (%.5f) %s' % stats['url']['min_ttfb']
    print 'URL max ttfb: (%.5f) %s' % stats['url']['max_ttfb']
    print 'URL min ttlb: (%.5f) %s' % stats['url']['min_ttlb']
    print 'URL max ttlb: (%.5f) %s' % stats['url']['max_ttlb']
    print 'NOTE: These stats are based on the average time (ttfb or ttlb) for each url.'
    print '\n'
    print 'Protocol stats:'
    for c in stats['code']:
        # Avoid None codes due to connection errors
        if c:
            print '\tHTTP %d: ' % c,
        else:
            print '\tURL fail: ',
        print '%5d requests (%5.2f%%)' % (stats['code'][c], 100*float(stats['code'][c])/total_requests)


    if dynamic_plot:
        print '\nPress ENTER to save data and exit.'
        sys.stdout.flush()
        sys.stdin.readline()
    
    dm.gp.reset()
    dm.gp.title('Requests: %d   User concurrency: %d   HTTP %.1f ' % (total_requests, concurrency, http_version/10.))
    dm.gp('set grid y')
    dm.gp('set ytics mirror 0,1,5')
    dm.gp('set ytics add (0.1)(0.2)(0.3)(0.4)(0.5)(0.6)(0.7)(0.8)(0.9) font ",8.0"')
    dm.gp.xlabel("requests")
    dm.gp.ylabel("response time (seconds)")
    dm.replot()
   
    # Saving information
    if test_id:
        file_prefix='%s_%s_r%d_c%d_http%d' %(test_id,host.split('://')[1],total_requests,concurrency,http_version)
    else:
        file_prefix='%s_r%d_c%d_http%d' %(host.split('://')[1],total_requests,concurrency,http_version)

    dm.save( file_prefix )
    

if __name__ == '__main__':
    try:
        opts = pw_getopts()
        pw_main( opts )
    except PywenchException as e:
        print 'Error:',e.__str__()
        sys.exit(1)
